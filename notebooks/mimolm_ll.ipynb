{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b82f689-a517-4ab6-8195-901533abaf9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'mimolm'...\n",
      "remote: Enumerating objects: 275, done.\u001b[K\n",
      "remote: Counting objects: 100% (275/275), done.\u001b[K\n",
      "remote: Compressing objects: 100% (164/164), done.\u001b[K\n",
      "remote: Total 275 (delta 139), reused 209 (delta 77), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (275/275), 340.44 KiB | 37.83 MiB/s, done.\n",
      "Resolving deltas: 100% (139/139), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/harshavardhan-patil/mimolm.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38231d66-5019-4986-adc6-ab8978e097bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/mimolm\n",
      "Branch 'feature/lambda' set up to track remote branch 'feature/lambda' from 'origin'.\n",
      "Switched to a new branch 'feature/lambda'\n"
     ]
    }
   ],
   "source": [
    "%cd mimolm\n",
    "!git checkout feature/lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d518ada-2607-4cf4-af25-a0809fe10153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting lightning\n",
      "  Downloading lightning-2.5.0.post0-py3-none-any.whl (815 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 KB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Requirement already satisfied: packaging<25.0,>=20.0 in /usr/lib/python3/dist-packages (from lightning) (21.3)\n",
      "Collecting pytorch-lightning\n",
      "  Downloading pytorch_lightning-2.5.0.post0-py3-none-any.whl (819 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.3/819.3 KB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Collecting torchmetrics<3.0,>=0.7.0\n",
      "  Downloading torchmetrics-1.6.1-py3-none-any.whl (927 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m927.3/927.3 KB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/lib/python3/dist-packages (from lightning) (4.9.0)\n",
      "Collecting lightning-utilities<2.0,>=0.10.0\n",
      "  Downloading lightning_utilities-0.12.0-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: torch<4.0,>=2.1.0 in /usr/lib/python3/dist-packages (from lightning) (2.5.1)\n",
      "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/lib/python3/dist-packages (from lightning) (5.4.1)\n",
      "Collecting tqdm<6.0,>=4.57.0\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 KB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec[http]<2026.0,>=2022.5.0 in /usr/lib/python3/dist-packages (from lightning) (2024.3.1)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
      "  Downloading aiohttp-3.11.12-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning) (59.6.0)\n",
      "Requirement already satisfied: numpy>1.20.0 in /usr/lib/python3/dist-packages (from torchmetrics<3.0,>=0.7.0->lightning) (1.21.5)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.6/126.6 KB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting async-timeout<6.0,>=4.0\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Collecting yarl<2.0,>=1.17.0\n",
      "  Downloading yarl-1.18.3-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (315 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.3/315.3 KB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting propcache>=0.2.0\n",
      "  Downloading propcache-0.2.1-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (204 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.8/204.8 KB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (240 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.9/240.9 KB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting aiohappyeyeballs>=2.3.0\n",
      "  Downloading aiohappyeyeballs-2.4.6-py3-none-any.whl (14 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/lib/python3/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (21.2.0)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/lib/python3/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (3.3)\n",
      "Installing collected packages: tqdm, propcache, multidict, lightning-utilities, frozenlist, async-timeout, aiohappyeyeballs, yarl, torchmetrics, aiosignal, aiohttp, pytorch-lightning, lightning\n",
      "Successfully installed aiohappyeyeballs-2.4.6 aiohttp-3.11.12 aiosignal-1.3.2 async-timeout-5.0.1 frozenlist-1.5.0 lightning-2.5.0.post0 lightning-utilities-0.12.0 multidict-6.1.0 propcache-0.2.1 pytorch-lightning-2.5.0.post0 torchmetrics-1.6.1 tqdm-4.67.1 yarl-1.18.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting loguru\n",
      "  Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 KB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Installing collected packages: loguru\n",
      "Successfully installed loguru-0.7.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting transforms3d\n",
      "  Downloading transforms3d-0.4.2-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /usr/lib/python3/dist-packages (from transforms3d) (1.21.5)\n",
      "Installing collected packages: transforms3d\n",
      "Successfully installed transforms3d-0.4.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting omegaconf\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 KB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.1.0 in /usr/lib/python3/dist-packages (from omegaconf) (5.4.1)\n",
      "Collecting antlr4-python3-runtime==4.9.*\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 KB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: antlr4-python3-runtime\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144575 sha256=fe6ef8916ea2931f0f0a2ec1f25f7a1be41371e6ef0b32ff3c786ff1ca04e563\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
      "Successfully built antlr4-python3-runtime\n",
      "Installing collected packages: antlr4-python3-runtime, omegaconf\n",
      "Successfully installed antlr4-python3-runtime-4.9.3 omegaconf-2.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensordict\n",
      "  Downloading tensordict-0.1.2-py3-none-any.whl (130 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.1/130.1 KB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/lib/python3/dist-packages (from tensordict) (1.21.5)\n",
      "Collecting cloudpickle\n",
      "  Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: torch in /usr/lib/python3/dist-packages (from tensordict) (2.5.1)\n",
      "Installing collected packages: cloudpickle, tensordict\n",
      "Successfully installed cloudpickle-3.1.1 tensordict-0.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch-kmeans\n",
      "  Downloading torch_kmeans-0.2.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: torch>=1.08 in /usr/lib/python3/dist-packages (from torch-kmeans) (2.5.1)\n",
      "Requirement already satisfied: numpy>=1.18 in /usr/lib/python3/dist-packages (from torch-kmeans) (1.21.5)\n",
      "Installing collected packages: torch-kmeans\n",
      "Successfully installed torch-kmeans-0.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install lightning\n",
    "%pip install python-dotenv\n",
    "%pip install loguru\n",
    "%pip install transforms3d\n",
    "%pip install omegaconf\n",
    "%pip install tensordict\n",
    "%pip install torch-kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b53a521d-4bba-4a82-ac65-c19d0dcf36a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from os.path  import join\n",
    "\n",
    "# Append the directory to your python path using sys\n",
    "sys.path.append('/home/ubuntu/mimolm')\n",
    "# Add the project root to sys.path\n",
    "print(Path.cwd()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "526eafd5-d33f-442b-9903-5844853cb8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-11 01:01:24.116\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mPROJ_ROOT path is: /home/ubuntu/mimolm\u001b[0m\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "You are using a CUDA device ('NVIDIA GH200 480GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "2025-02-11 01:01:26.808557: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1739235686.816741   13593 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1739235686.820389   13593 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type               | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | preprocessor      | Sequential         | 0      | train\n",
      "1 | input_projections | InputProjections   | 123 K  | train\n",
      "2 | encoder           | EarlyFusionEncoder | 611 K  | train\n",
      "3 | decoder           | MotionDecoder      | 568 K  | train\n",
      "4 | logsoftmax        | LogSoftmax         | 0      | train\n",
      "5 | criterion         | NLLLoss            | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "1.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 M     Total params\n",
      "5.216     Total estimated model params size (MB)\n",
      "102       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/196 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/lightning/pytorch/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 128. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 196/196 [01:53<00:00,  1.73it/s, v_num=1, train_loss=1.190]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/lightning/pytorch/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 28. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 196/196 [01:53<00:00,  1.73it/s, v_num=1, train_loss=1.190]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FIT Profiler Report\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  Action                                                                                                                                                        \t|  Mean duration (s)\t|  Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  Total                                                                                                                                                         \t|  -              \t|  8284           \t|  115.81         \t|  100 %          \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  run_training_epoch                                                                                                                                            \t|  113.23         \t|  1              \t|  113.23         \t|  97.775         \t|\n",
      "|  run_training_batch                                                                                                                                            \t|  0.56626        \t|  196            \t|  110.99         \t|  95.838         \t|\n",
      "|  [LightningModule]MimoLM.optimizer_step                                                                                                                        \t|  0.56598        \t|  196            \t|  110.93         \t|  95.791         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.training_step                                                                                                                  \t|  0.21381        \t|  196            \t|  41.906         \t|  36.186         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.backward                                                                                                                       \t|  0.016745       \t|  196            \t|  3.282          \t|  2.834          \t|\n",
      "|  [_TrainingEpochLoop].train_dataloader_next                                                                                                                    \t|  0.0094451      \t|  196            \t|  1.8512         \t|  1.5986         \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_batch_end                                                                                                                  \t|  0.00095901     \t|  196            \t|  0.18797        \t|  0.16231        \t|\n",
      "|  [Strategy]SingleDeviceStrategy.batch_to_device                                                                                                                \t|  0.00045486     \t|  196            \t|  0.089153       \t|  0.076984       \t|\n",
      "|  [LightningModule]MimoLM.transfer_batch_to_device                                                                                                              \t|  0.00042318     \t|  196            \t|  0.082944       \t|  0.071623       \t|\n",
      "|  [LightningModule]MimoLM.optimizer_zero_grad                                                                                                                   \t|  0.00014231     \t|  196            \t|  0.027892       \t|  0.024085       \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_epoch_end      \t|  0.02374        \t|  1              \t|  0.02374        \t|  0.0205         \t|\n",
      "|  save_checkpoint                                                                                                                                               \t|  0.022771       \t|  1              \t|  0.022771       \t|  0.019663       \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_start                                                                                                                      \t|  0.0079772      \t|  1              \t|  0.0079772      \t|  0.0068884      \t|\n",
      "|  [LightningModule]MimoLM.configure_gradient_clipping                                                                                                           \t|  1.9471e-05     \t|  196            \t|  0.0038162      \t|  0.0032954      \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_batch_end      \t|  1.8728e-05     \t|  196            \t|  0.0036707      \t|  0.0031697      \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_epoch_end                                                                                                                  \t|  0.0022118      \t|  1              \t|  0.0022118      \t|  0.0019099      \t|\n",
      "|  [Callback]ModelSummary.on_fit_start                                                                                                                           \t|  0.0020609      \t|  1              \t|  0.0020609      \t|  0.0017796      \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_epoch_start                                                                                                                \t|  0.0014961      \t|  1              \t|  0.0014961      \t|  0.0012919      \t|\n",
      "|  [Callback]LearningRateMonitor.on_train_epoch_start                                                                                                            \t|  0.0010382      \t|  1              \t|  0.0010382      \t|  0.00089649     \t|\n",
      "|  [Callback]LearningRateMonitor.on_train_batch_start                                                                                                            \t|  4.5971e-06     \t|  196            \t|  0.00090104     \t|  0.00077805     \t|\n",
      "|  [Callback]ModelSummary.on_train_batch_end                                                                                                                     \t|  3.057e-06      \t|  196            \t|  0.00059918     \t|  0.00051739     \t|\n",
      "|  [Callback]LearningRateMonitor.on_after_backward                                                                                                               \t|  2.6748e-06     \t|  196            \t|  0.00052426     \t|  0.0004527      \t|\n",
      "|  [Callback]LearningRateMonitor.on_before_zero_grad                                                                                                             \t|  2.3615e-06     \t|  196            \t|  0.00046286     \t|  0.00039968     \t|\n",
      "|  [Callback]LearningRateMonitor.on_train_batch_end                                                                                                              \t|  2.2861e-06     \t|  196            \t|  0.00044807     \t|  0.00038691     \t|\n",
      "|  [Callback]LearningRateMonitor.on_before_optimizer_step                                                                                                        \t|  1.9228e-06     \t|  196            \t|  0.00037687     \t|  0.00032543     \t|\n",
      "|  [Callback]LearningRateMonitor.on_before_backward                                                                                                              \t|  1.8136e-06     \t|  196            \t|  0.00035546     \t|  0.00030694     \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_end                                                                                                                        \t|  0.00035111     \t|  1              \t|  0.00035111     \t|  0.00030319     \t|\n",
      "|  [LightningModule]MimoLM.configure_optimizers                                                                                                                  \t|  0.00026234     \t|  1              \t|  0.00026234     \t|  0.00022653     \t|\n",
      "|  [Callback]LearningRateMonitor.on_train_start                                                                                                                  \t|  0.00025904     \t|  1              \t|  0.00025904     \t|  0.00022369     \t|\n",
      "|  [LightningModule]MimoLM.on_before_batch_transfer                                                                                                              \t|  1.2624e-06     \t|  196            \t|  0.00024743     \t|  0.00021366     \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_batch_start                                                                                                                \t|  1.0691e-06     \t|  196            \t|  0.00020954     \t|  0.00018094     \t|\n",
      "|  [LightningModule]MimoLM.on_after_batch_transfer                                                                                                               \t|  9.5937e-07     \t|  196            \t|  0.00018804     \t|  0.00016237     \t|\n",
      "|  [LightningModule]MimoLM.on_train_batch_end                                                                                                                    \t|  9.2002e-07     \t|  196            \t|  0.00018032     \t|  0.00015571     \t|\n",
      "|  [LightningModule]MimoLM.on_after_backward                                                                                                                     \t|  8.6972e-07     \t|  196            \t|  0.00017047     \t|  0.0001472      \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_optimizer_step                                                                                                            \t|  8.6434e-07     \t|  196            \t|  0.00016941     \t|  0.00014629     \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_zero_grad                                                                                                                 \t|  8.552e-07      \t|  196            \t|  0.00016762     \t|  0.00014474     \t|\n",
      "|  [Callback]TQDMProgressBar.on_after_backward                                                                                                                   \t|  8.3008e-07     \t|  196            \t|  0.0001627      \t|  0.00014049     \t|\n",
      "|  [LightningModule]MimoLM.on_before_zero_grad                                                                                                                   \t|  8.2434e-07     \t|  196            \t|  0.00016157     \t|  0.00013952     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_zero_grad     \t|  8.0115e-07     \t|  196            \t|  0.00015703     \t|  0.00013559     \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_backward                                                                                                                  \t|  7.7732e-07     \t|  196            \t|  0.00015235     \t|  0.00013156     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_batch_start                                                                                                           \t|  7.5757e-07     \t|  196            \t|  0.00014848     \t|  0.00012822     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_backward      \t|  7.267e-07      \t|  196            \t|  0.00014243     \t|  0.00012299     \t|\n",
      "|  [Callback]ModelSummary.on_after_backward                                                                                                                      \t|  7.1724e-07     \t|  196            \t|  0.00014058     \t|  0.00012139     \t|\n",
      "|  [LightningModule]MimoLM.on_before_backward                                                                                                                    \t|  7.1528e-07     \t|  196            \t|  0.00014019     \t|  0.00012106     \t|\n",
      "|  [LightningModule]MimoLM.on_before_optimizer_step                                                                                                              \t|  7.0661e-07     \t|  196            \t|  0.0001385      \t|  0.00011959     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_optimizer_step\t|  6.991e-07      \t|  196            \t|  0.00013702     \t|  0.00011832     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_batch_start    \t|  6.9388e-07     \t|  196            \t|  0.000136       \t|  0.00011744     \t|\n",
      "|  [Callback]ModelSummary.on_before_zero_grad                                                                                                                    \t|  6.5421e-07     \t|  196            \t|  0.00012823     \t|  0.00011072     \t|\n",
      "|  [Callback]ModelSummary.on_train_batch_start                                                                                                                   \t|  6.2988e-07     \t|  196            \t|  0.00012346     \t|  0.00010661     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_after_backward       \t|  6.201e-07      \t|  196            \t|  0.00012154     \t|  0.00010495     \t|\n",
      "|  [Callback]ModelSummary.on_before_optimizer_step                                                                                                               \t|  6.1601e-07     \t|  196            \t|  0.00012074     \t|  0.00010426     \t|\n",
      "|  [Callback]ModelSummary.on_before_backward                                                                                                                     \t|  6.0426e-07     \t|  196            \t|  0.00011843     \t|  0.00010227     \t|\n",
      "|  [LightningModule]MimoLM.on_train_batch_start                                                                                                                  \t|  5.9953e-07     \t|  196            \t|  0.00011751     \t|  0.00010147     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.setup                   \t|  0.00011367     \t|  1              \t|  0.00011367     \t|  9.8151e-05     \t|\n",
      "|  [LightningModule]MimoLM.lr_scheduler_step                                                                                                                     \t|  7.0849e-05     \t|  1              \t|  7.0849e-05     \t|  6.1179e-05     \t|\n",
      "|  [Callback]ModelSummary.on_train_start                                                                                                                         \t|  7.136e-06      \t|  1              \t|  7.136e-06      \t|  6.162e-06      \t|\n",
      "|  [Callback]TQDMProgressBar.setup                                                                                                                               \t|  5.12e-06       \t|  1              \t|  5.12e-06       \t|  4.4212e-06     \t|\n",
      "|  [Callback]LearningRateMonitor.on_fit_end                                                                                                                      \t|  4.544e-06      \t|  1              \t|  4.544e-06      \t|  3.9238e-06     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_start          \t|  4.256e-06      \t|  1              \t|  4.256e-06      \t|  3.6751e-06     \t|\n",
      "|  [Callback]LearningRateMonitor.setup                                                                                                                           \t|  4.096e-06      \t|  1              \t|  4.096e-06      \t|  3.5369e-06     \t|\n",
      "|  [Callback]ModelSummary.on_train_epoch_start                                                                                                                   \t|  3.392e-06      \t|  1              \t|  3.392e-06      \t|  2.929e-06      \t|\n",
      "|  [Callback]LearningRateMonitor.on_train_end                                                                                                                    \t|  2.848e-06      \t|  1              \t|  2.848e-06      \t|  2.4593e-06     \t|\n",
      "|  [Callback]ModelSummary.on_train_epoch_end                                                                                                                     \t|  2.816e-06      \t|  1              \t|  2.816e-06      \t|  2.4316e-06     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_fit_start            \t|  2.688e-06      \t|  1              \t|  2.688e-06      \t|  2.3211e-06     \t|\n",
      "|  [Callback]LearningRateMonitor.on_fit_start                                                                                                                    \t|  2.529e-06      \t|  1              \t|  2.529e-06      \t|  2.1838e-06     \t|\n",
      "|  [Callback]LearningRateMonitor.on_save_checkpoint                                                                                                              \t|  2.496e-06      \t|  1              \t|  2.496e-06      \t|  2.1553e-06     \t|\n",
      "|  [Callback]ModelSummary.on_train_end                                                                                                                           \t|  2.368e-06      \t|  1              \t|  2.368e-06      \t|  2.0448e-06     \t|\n",
      "|  [LightningModule]MimoLM.setup                                                                                                                                 \t|  1.856e-06      \t|  1              \t|  1.856e-06      \t|  1.6027e-06     \t|\n",
      "|  [Callback]LearningRateMonitor.teardown                                                                                                                        \t|  1.76e-06       \t|  1              \t|  1.76e-06       \t|  1.5198e-06     \t|\n",
      "|  [LightningModule]MimoLM.configure_callbacks                                                                                                                   \t|  1.728e-06      \t|  1              \t|  1.728e-06      \t|  1.4921e-06     \t|\n",
      "|  [Callback]LearningRateMonitor.on_train_epoch_end                                                                                                              \t|  1.504e-06      \t|  1              \t|  1.504e-06      \t|  1.2987e-06     \t|\n",
      "|  [LightningModule]MimoLM.on_train_epoch_start                                                                                                                  \t|  1.44e-06       \t|  1              \t|  1.44e-06       \t|  1.2435e-06     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_start                                                                                                                 \t|  1.184e-06      \t|  1              \t|  1.184e-06      \t|  1.0224e-06     \t|\n",
      "|  [LightningModule]MimoLM.on_fit_start                                                                                                                          \t|  1.152e-06      \t|  1              \t|  1.152e-06      \t|  9.9476e-07     \t|\n",
      "|  [LightningModule]MimoLM.on_train_start                                                                                                                        \t|  1.12e-06       \t|  1              \t|  1.12e-06       \t|  9.6713e-07     \t|\n",
      "|  [LightningModule]MimoLM.teardown                                                                                                                              \t|  1.12e-06       \t|  1              \t|  1.12e-06       \t|  9.6713e-07     \t|\n",
      "|  [Callback]ModelSummary.setup                                                                                                                                  \t|  1.088e-06      \t|  1              \t|  1.088e-06      \t|  9.395e-07      \t|\n",
      "|  [Callback]TQDMProgressBar.on_save_checkpoint                                                                                                                  \t|  1.088e-06      \t|  1              \t|  1.088e-06      \t|  9.395e-07      \t|\n",
      "|  [LightningModule]MimoLM.on_train_end                                                                                                                          \t|  1.056e-06      \t|  1              \t|  1.056e-06      \t|  9.1186e-07     \t|\n",
      "|  [Callback]ModelSummary.on_fit_end                                                                                                                             \t|  9.6e-07        \t|  1              \t|  9.6e-07        \t|  8.2897e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_end            \t|  9.28e-07       \t|  1              \t|  9.28e-07       \t|  8.0133e-07     \t|\n",
      "|  [Callback]TQDMProgressBar.on_fit_end                                                                                                                          \t|  9.28e-07       \t|  1              \t|  9.28e-07       \t|  8.0133e-07     \t|\n",
      "|  [LightningModule]MimoLM.on_train_epoch_end                                                                                                                    \t|  8.96e-07       \t|  1              \t|  8.96e-07       \t|  7.737e-07      \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_end                                                                                                                   \t|  8.96e-07       \t|  1              \t|  8.96e-07       \t|  7.737e-07      \t|\n",
      "|  [LightningModule]MimoLM.on_fit_end                                                                                                                            \t|  8.64e-07       \t|  1              \t|  8.64e-07       \t|  7.4607e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_epoch_start    \t|  7.68e-07       \t|  1              \t|  7.68e-07       \t|  6.6317e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_save_checkpoint      \t|  7.36e-07       \t|  1              \t|  7.36e-07       \t|  6.3554e-07     \t|\n",
      "|  [Callback]TQDMProgressBar.teardown                                                                                                                            \t|  7.36e-07       \t|  1              \t|  7.36e-07       \t|  6.3554e-07     \t|\n",
      "|  [Callback]TQDMProgressBar.on_fit_start                                                                                                                        \t|  7.04e-07       \t|  1              \t|  7.04e-07       \t|  6.0791e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_fit_end              \t|  7.04e-07       \t|  1              \t|  7.04e-07       \t|  6.0791e-07     \t|\n",
      "|  [Callback]ModelSummary.teardown                                                                                                                               \t|  6.72e-07       \t|  1              \t|  6.72e-07       \t|  5.8028e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.teardown                \t|  6.4e-07        \t|  1              \t|  6.4e-07        \t|  5.5264e-07     \t|\n",
      "|  [Callback]ModelSummary.on_save_checkpoint                                                                                                                     \t|  6.4e-07        \t|  1              \t|  6.4e-07        \t|  5.5264e-07     \t|\n",
      "|  [LightningModule]MimoLM.on_save_checkpoint                                                                                                                    \t|  5.76e-07       \t|  1              \t|  5.76e-07       \t|  4.9738e-07     \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.external.hptr.src.data_modules.data_h5_av2 import DataH5av2\n",
    "from src.mimolm import MimoLM\n",
    "import lightning as pl\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "import time\n",
    "import torch\n",
    "import tqdm\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, LearningRateMonitor\n",
    "\n",
    "data_module = DataH5av2(\"/home/ubuntu/mimolm/data\")\n",
    "data_module.setup(stage=\"fit\")\n",
    "train_loader = data_module.train_dataloader()\n",
    "#val_loader = data_module.val_dataloader()\n",
    "\n",
    "\n",
    "model = MimoLM(data_size=data_module.tensor_size_train\n",
    "               , n_rollouts = 1\n",
    "               , learning_rate = 1.e-04,)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    save_top_k=-1,  # Save all checkpoints\n",
    "    every_n_epochs=1  # Save checkpoint every n epochs\n",
    ")\n",
    "lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
    "trainer = pl.Trainer(precision='16-mixed',\n",
    "                     callbacks=[checkpoint_callback, lr_monitor],\n",
    "                     max_epochs=1,\n",
    "                     profiler=\"simple\",)\n",
    "                     #default_root_dir=\"/content/drive/MyDrive/Colab/mimolm/ckpts\")\n",
    "# tuner = Tuner(trainer)\n",
    "\n",
    "# #Run learning rate finder and then train\n",
    "# lr_finder = tuner.lr_find(model=model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "trainer.fit(model=model, train_dataloaders=train_loader), #val_dataloaders=val_loader)#, ckpt_path='/content/drive/MyDrive/Colab/mimolm/ckpts/lightning_logs/version_1/checkpoints/epoch=4-step=20825.ckpt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a781f96-2bae-4b33-a5d2-5df8e5550a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73d3176-e92e-49fd-b869-68e816341e71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
